{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling for Deployment Example\n",
    "This notebook shows the basic outline for training a model, evaluating it, then using it in a \"production\" context to make predictions about new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract, Transform, Load Data\n",
    "This is easy here because I'm using a nice tidy dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get premade wine dataset from sklearn\n",
    "data = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a Model to Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build a model to predict the class of wine\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data,\n",
    "                                                    data.target,\n",
    "                                                    random_state=2019)\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=None, random_state=0, n_estimators=100)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate the Model\n",
    "Not necessarily the most realistic performance, but let's go with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, rf_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, rf_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export the Model\n",
    "As far as I can tell, the [`pickle` format](https://docs.python.org/3/library/pickle.html) it most popular for this task in Python right now.  Pickling is a form of serialization or flattening, which basically means converting everything about an object in memory into bits of data that can be stored in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wine_classifier.pickle\", \"wb\") as f: # \"wb\" means \"write as bytes\"\n",
    "    pickle.dump(rf_clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load the Model\n",
    "This part would actually almost never be in the same file as the previous step.  The goal is to take information that was stored in memory at one time, then save it so it can be used later.  Here specifically this is useful because training a model is usually a lot slower than using the model to make a prediction, so this saves us from having to re-run that costly operation each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wine_classifier.pickle\", \"rb\") as f:  # \"rb\" means \"read as bytes\"\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make a Prediction with the Loaded Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I'm constructing a request JSON that resembles what would come from a user who wants a predicted class of wine based on these feature values.  This code would not actually exist in your deployed application, it would be created automatically by whatever protocol generated the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a fake request JSON from the user with all the headings\n",
    "expected_features = (\"Alcohol\", \"Malic acid\", \"Ash\", \"Alcalinity of ash\", \\\n",
    "        \"Magnesium\", \"Total phenols\", \"Flavanoids\", \"Nonflavanoid phenols\", \\\n",
    "        \"Proanthocyanins\", \"Color intensity\", \"Hue\", \\\n",
    "        \"OD280/OD315 of diluted wines\", \"Proline\")\n",
    "\n",
    "example_values = [1.282e+01, 3.370e+00, 2.300e+00, 1.950e+01, 8.800e+01, 1.480e+00, \\\n",
    "       6.600e-01, 4.000e-01, 9.700e-01, 1.026e+01, 7.200e-01, 1.750e+00, \\\n",
    "       6.850e+02]\n",
    "\n",
    "request_json = {feature: value \n",
    "                for feature, value in zip(expected_features, example_values)}\n",
    "request_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the section that more closely resembles what you might have in your application.  I'm checking to make sure that the expected values are in the `request_json`, transforming them into the right format to make a prediction, then printing out that prediction.  In your actual deployed code, you would most likely be returning the response, not printing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if request_json and all(feature in request_json for feature in expected_features):\n",
    "    # unpack all of the relevant values from the request into a list\n",
    "    test_value = [request_json[feature] for feature in expected_features]\n",
    "    \n",
    "    # make a prediction from the \"user input\"\n",
    "    predicted_class = int(loaded_model.predict([test_value])[0])\n",
    "    \n",
    "    # construct a response\n",
    "    response_json = {\"prediction\": predicted_class}\n",
    "    print(response_json)\n",
    "else:\n",
    "    print(\"something was missing from the request\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But we have more than one classifier model!\n",
    "\n",
    "Let's try building three more classifiers:\n",
    "* DecisionTreeClassifier\n",
    "* LogisticRegression\n",
    "* GradientBoosting\n",
    "\n",
    "### First let's do the `DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=2019)\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onto the `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(solver=\"newton-cg\", multi_class=\"multinomial\", random_state=2019)\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's add the `GradientBoostingClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state=2019)\n",
    "gb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can finally evaluate all of our classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_labels = [\"DecisionTreeClassifier\",\n",
    "              \"LogisticRegression\",\n",
    "              \"GradientBoostingClassifier\",\n",
    "              \"RandomForestClassifier\"]\n",
    "clf_models = [dt_clf, lr_clf, gb_clf, rf_clf]\n",
    "\n",
    "for label, clf in zip(clf_labels, clf_models):\n",
    "    print(label)\n",
    "    print(metrics.classification_report(y_test, clf.predict(X_test)))\n",
    "    print(\"======================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
